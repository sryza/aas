{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218aaf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a4bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").appName('chapter_7').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c638045a",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_raw = spark.read.option(\"header\", \"true\").csv(\"taxidata\")\n",
    "taxi_raw.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fun\n",
    "\n",
    "taxi_raw = taxi_raw.withColumn('pickup_datetime',\n",
    "                                fun.to_timestamp(fun.col('pickup_datetime'),\n",
    "                                                \"yyyy-MM-dd HH:mm:ss\"))\n",
    "taxi_raw = taxi_raw.withColumn('dropoff_datetime',\n",
    "                                fun.to_timestamp(fun.col('dropoff_datetime'),\n",
    "                                                \"yyyy-MM-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73251f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dcb101",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_raw.sort(fun.col(\"pickup_datetime\").desc()).show(3, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8b6005",
   "metadata": {},
   "outputs": [],
   "source": [
    "geospatial_temporal_colnames = [\"pickup_longitude\", \"pickup_latitude\", \\\n",
    "                                \"dropoff_longitude\", \"dropoff_latitude\", \\\n",
    "                                \"pickup_datetime\", \"dropoff_datetime\"]\n",
    "taxi_raw.select([fun.count(fun.when(fun.isnull(c), c)).\\\n",
    "                            alias(c) for c in geospatial_temporal_colnames]).\\\n",
    "                show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18877af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_raw = taxi_raw.na.drop(subset=geospatial_temporal_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e33d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Count of zero dropoff, pickup latitude and longitude records\")\n",
    "taxi_raw.groupBy((fun.col(\"dropoff_longitude\") == 0) |\n",
    "  (fun.col(\"dropoff_latitude\") == 0) |\n",
    "  (fun.col(\"pickup_longitude\") == 0) |\n",
    "  (fun.col(\"pickup_latitude\") == 0)).\\\n",
    "    count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081225b7",
   "metadata": {},
   "source": [
    "### Geospatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d27f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! head -n 7 nyc-boroughs.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gdp\n",
    "\n",
    "gdf = gdp.read_file(\"nyc-boroughs.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4b0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.to_crs(3857)\n",
    "\n",
    "gdf['area'] = gdf.apply(lambda x: x['geometry'].area, axis=1)\n",
    "gdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.sort_values(by=['boroughCode', 'area'], ascending=[True, False])\n",
    "gdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "b_gdf = spark.sparkContext.broadcast(gdf)\n",
    "\n",
    "def find_borough(latitude,longitude):\n",
    "    mgdf = b_gdf.value.apply(lambda x: x['borough'] if \\\n",
    "                              x['geometry'].\\\n",
    "                              intersects(gdp.\\\n",
    "                                        points_from_xy(\n",
    "                                            [longitude], \\\n",
    "                                            [latitude])[0]) \\\n",
    "                              else None, axis=1)\n",
    "    idx = mgdf.first_valid_index()\n",
    "    return mgdf.loc[idx] if idx is not None else None\n",
    "\n",
    "find_borough_udf = fun.udf(find_borough, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23618117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_with_boroughs = taxi_raw.\\\n",
    "                    withColumn(\"dropoff_borough\", \\\n",
    "                              find_borough_udf(\n",
    "                                fun.col(\"dropoff_latitude\"),\\\n",
    "                                fun.col('dropoff_longitude')))\n",
    "\n",
    "df_with_boroughs.groupBy(fun.col(\"dropoff_borough\")).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e3cec",
   "metadata": {},
   "source": [
    "### Sessionization in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30836762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "window_spec = Window.partitionBy(\"hack_license\").\\\n",
    "                      orderBy(fun.col(\"hack_license\"),\n",
    "                              fun.col(\"pickup_datetime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206bdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a41fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_borough_durations = df_with_boroughs.\\\n",
    "            withColumn(\"trip_time_difference\", \\\n",
    "            fun.col(\"pickup_datetime\") - fun.lag(fun.col(\"pickup_datetime\"),\n",
    "                                          1). \\\n",
    "            over(window_spec)).show(50, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_borough_durations.\\\n",
    "  selectExpr(\"floor(seconds / 3600) as hours\").\\\n",
    "    groupBy(\"hours\").\\\n",
    "    count().\\\n",
    "    sort(\"hours\").\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, stddev\n",
    "\n",
    "df_with_borough_durations.\\\n",
    "    where(\"seconds > 0 AND seconds < 60*60*4\").\\\n",
    "    groupBy(\"borough\").\\\n",
    "    agg(avg(\"seconds\"), stddev(\"seconds\")).\\\n",
    "    show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
