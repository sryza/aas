{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b1592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").appName('chapter_4').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e4041",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba888365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_without_header = spark.read.option(\"inferSchema\", True)\\\n",
    "                      .option(\"header\", False).csv(\"data/covtype.data\")\n",
    "data_without_header.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "colnames = [\"Elevation\", \"Aspect\", \"Slope\", \\\n",
    "            \"Horizontal_Distance_To_Hydrology\", \\\n",
    "            \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\", \\\n",
    "            \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\", \\\n",
    "            \"Horizontal_Distance_To_Fire_Points\"] + \\\n",
    "[f\"Wilderness_Area_{i}\" for i in range(4)] + \\\n",
    "[f\"Soil_Type_{i}\" for i in range(40)] + \\\n",
    "[\"Cover_Type\"]\n",
    "\n",
    "data = data_without_header.toDF(*colnames).\\\n",
    "                          withColumn(\"Cover_Type\",\n",
    "                                    col(\"Cover_Type\").cast(DoubleType()))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31635e8e",
   "metadata": {},
   "source": [
    "### Our First Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, test_data) = data.randomSplit([0.9, 0.1])\n",
    "train_data.cache()\n",
    "test_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29011fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "input_cols = colnames[:-1]\n",
    "vector_assembler = VectorAssembler(inputCols=input_cols,\n",
    "                                    outputCol=\"featureVector\")\n",
    "\n",
    "assembled_train_data = vector_assembler.transform(train_data)\n",
    "\n",
    "assembled_train_data.select(\"featureVector\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa48d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(seed = 1234, labelCol=\"Cover_Type\",\n",
    "                                    featuresCol=\"featureVector\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "\n",
    "model = classifier.fit(assembled_train_data)\n",
    "print(model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30159191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(model.featureImportances.toArray(),\n",
    "            index=input_cols, columns=['importance']).\\\n",
    "            sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63d373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(assembled_train_data)\n",
    "predictions.select(\"Cover_Type\", \"prediction\", \"probability\").\\\n",
    "            show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\",\n",
    "                                        predictionCol=\"prediction\")\n",
    "\n",
    "evaluator.setMetricName(\"accuracy\").evaluate(predictions)\n",
    "evaluator.setMetricName(\"f1\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = predictions.groupBy(\"Cover_Type\").\\\n",
    "  pivot(\"prediction\", range(1,8)).count().\\\n",
    "  na.fill(0.0).\\\n",
    "  orderBy(\"Cover_Type\")\n",
    "\n",
    "confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b3479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def class_probabilities(data):\n",
    "    total = data.count()\n",
    "    return data.groupBy(\"Cover_Type\").count().\\\n",
    "    orderBy(\"Cover_Type\").\\\n",
    "    select(col(\"count\").cast(DoubleType())).\\\n",
    "    withColumn(\"count_proportion\", col(\"count\")/total).\\\n",
    "    select(\"count_proportion\").collect()\n",
    "\n",
    "\n",
    "train_prior_probabilities = class_probabilities(train_data)\n",
    "test_prior_probabilities = class_probabilities(test_data)\n",
    "\n",
    "train_prior_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prior_probabilities = [p[0] for p in train_prior_probabilities]\n",
    "test_prior_probabilities = [p[0] for p in test_prior_probabilities]\n",
    "\n",
    "sum([train_p * cv_p for train_p, cv_p in zip(train_prior_probabilities,\n",
    "                                              test_prior_probabilities)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db4971a",
   "metadata": {},
   "source": [
    "### Tuning Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e81276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"featureVector\")\n",
    "classifier = DecisionTreeClassifier(seed=1234, labelCol=\"Cover_Type\",\n",
    "                                    featuresCol=\"featureVector\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa3e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "paramGrid = ParamGridBuilder(). \\\n",
    "  addGrid(classifier.impurity, [\"gini\", \"entropy\"]). \\\n",
    "  addGrid(classifier.maxDepth, [1, 20]). \\\n",
    "  addGrid(classifier.maxBins, [40, 300]). \\\n",
    "  addGrid(classifier.minInfoGain, [0.0, 0.05]). \\\n",
    "  build()\n",
    "\n",
    "multiclassEval = MulticlassClassificationEvaluator(). \\\n",
    "  setLabelCol(\"Cover_Type\"). \\\n",
    "  setPredictionCol(\"prediction\"). \\\n",
    "  setMetricName(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6cbb6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "\n",
    "validator = TrainValidationSplit(seed=1234,\n",
    "  estimator=pipeline,\n",
    "  evaluator=multiclassEval,\n",
    "  estimatorParamMaps=paramGrid,\n",
    "  trainRatio=0.9)\n",
    "\n",
    "validator_model = validator.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0786e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "best_model = validator_model.bestModel\n",
    "pprint(best_model.stages[1].extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b339bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validator_model = validator.fit(train_data)\n",
    "\n",
    "metrics = validator_model.validationMetrics\n",
    "params = validator_model.getEstimatorParamMaps()\n",
    "metrics_and_params = list(zip(metrics, params))\n",
    "\n",
    "metrics_and_params.sort(key=lambda x: x[0], reverse=True)\n",
    "metrics_and_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58a0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.sort(reverse=True)\n",
    "print(metrics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclassEval.evaluate(best_model.transform(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba974c3",
   "metadata": {},
   "source": [
    "### Categorical Features Revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a5f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def unencode_one_hot(data):\n",
    "    wilderness_cols = ['Wilderness_Area_' + str(i) for i in range(4)]\n",
    "    wilderness_assembler = VectorAssembler().\\\n",
    "                            setInputCols(wilderness_cols).\\\n",
    "                            setOutputCol(\"wilderness\")\n",
    "\n",
    "    unhot_udf = udf(lambda v: v.toArray().tolist().index(1))\n",
    "\n",
    "    with_wilderness = wilderness_assembler.transform(data).\\\n",
    "      drop(*wilderness_cols).\\\n",
    "      withColumn(\"wilderness\", unhot_udf(col(\"wilderness\")).cast(IntegerType()))\n",
    "\n",
    "    soil_cols = ['Soil_Type_' + str(i) for i in range(40)]\n",
    "    soil_assembler = VectorAssembler().\\\n",
    "                      setInputCols(soil_cols).\\\n",
    "                      setOutputCol(\"soil\")\n",
    "    with_soil = soil_assembler.\\\n",
    "                transform(with_wilderness).\\\n",
    "                drop(*soil_cols).\\\n",
    "                withColumn(\"soil\", unhot_udf(col(\"soil\")).cast(IntegerType()))\n",
    "\n",
    "    return with_soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ce5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unenc_train_data = unencode_one_hot(train_data)\n",
    "unenc_train_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04f8f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "unenc_train_data.groupBy('wilderness').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "cols = unenc_train_data.columns\n",
    "input_cols = [c for c in cols if c!='Cover_Type']\n",
    "\n",
    "assembler = VectorAssembler().setInputCols(input_cols).setOutputCol(\"featureVector\")\n",
    "\n",
    "indexer = VectorIndexer().\\\n",
    "  setMaxCategories(40).\\\n",
    "  setInputCol(\"featureVector\").setOutputCol(\"indexedVector\")\n",
    "\n",
    "classifier = DecisionTreeClassifier().setLabelCol(\"Cover_Type\").\\\n",
    "                                      setFeaturesCol(\"indexedVector\").\\\n",
    "                                      setPredictionCol(\"prediction\")\n",
    "\n",
    "pipeline = Pipeline().setStages([assembler, indexer, classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a449fc",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6380f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(seed=1234, labelCol=\"Cover_Type\",\n",
    "                                    featuresCol=\"indexedVector\",\n",
    "                                    predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "unenc_train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea2195a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Skipped in book\n",
    "\n",
    "cols = unenc_train_data.columns\n",
    "input_cols = [c for c in cols if c!='Cover_Type']\n",
    "\n",
    "assembler = VectorAssembler().setInputCols(input_cols).setOutputCol(\"featureVector\")\n",
    "\n",
    "indexer = VectorIndexer().\\\n",
    "  setMaxCategories(40).\\\n",
    "  setInputCol(\"featureVector\").setOutputCol(\"indexedVector\")\n",
    "\n",
    "pipeline = Pipeline().setStages([assembler, indexer, classifier])\n",
    "\n",
    "paramGrid = ParamGridBuilder(). \\\n",
    "  addGrid(classifier.impurity, [\"gini\", \"entropy\"]). \\\n",
    "  addGrid(classifier.maxDepth, [1, 20]). \\\n",
    "  addGrid(classifier.maxBins, [40, 300]). \\\n",
    "  addGrid(classifier.minInfoGain, [0.0, 0.05]). \\\n",
    "  build()\n",
    "\n",
    "multiclassEval = MulticlassClassificationEvaluator(). \\\n",
    "  setLabelCol(\"Cover_Type\"). \\\n",
    "  setPredictionCol(\"prediction\"). \\\n",
    "  setMetricName(\"accuracy\")\n",
    "\n",
    "validator = TrainValidationSplit(seed=1234,\n",
    "  estimator=pipeline,\n",
    "  evaluator=multiclassEval,\n",
    "  estimatorParamMaps=paramGrid,\n",
    "  trainRatio=0.9)\n",
    "\n",
    "validator_model = validator.fit(unenc_train_data)\n",
    "\n",
    "best_model = validator_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48154d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forest_model = best_model.stages[2]\n",
    "\n",
    "feature_importance_list = list(zip(input_cols,\n",
    "                                  forest_model.featureImportances.toArray()))\n",
    "feature_importance_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pprint(feature_importance_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9bdd5b",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b33e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "unenc_test_data = unencode_one_hot(test_data)\n",
    "\n",
    "best_model.transform(unenc_test_data.drop(\"Cover_Type\")).\\\n",
    "                    select(\"prediction\").show(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
